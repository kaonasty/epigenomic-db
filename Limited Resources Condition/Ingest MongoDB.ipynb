{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [2:33:53<00:00, 131.90s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ingestion complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Setup\n",
    "CSV_DIR = \"E:/DataTesis/Final_Epigenomic\"  # E:\\DataTesis\\Final_Epigenomic\n",
    "MONGO_URI = \"mongodb://localhost:27017\"\n",
    "DB_NAME = \"epigenomic_db\"\n",
    "\n",
    "client = MongoClient(MONGO_URI)\n",
    "db = client[DB_NAME]\n",
    "region_col = db.Region\n",
    "feature_col = db.EpigenomicFeatures\n",
    "\n",
    "region_counter = 0\n",
    "\n",
    "# Iterate over files\n",
    "for filename in tqdm(os.listdir(CSV_DIR)):\n",
    "    if not filename.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    # Parse metadata from filename: A549_1024_promoter_epigenomic.csv\n",
    "    try:\n",
    "        base = filename.replace(\"_epigenomic.csv\", \"\")\n",
    "        cell_line, window_size, region_type = base.split(\"_\")\n",
    "    except ValueError:\n",
    "        print(f\"Skipping file with bad name: {filename}\")\n",
    "        continue\n",
    "\n",
    "    # Load CSV\n",
    "    filepath = os.path.join(CSV_DIR, filename)\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        region_id = f\"{cell_line}_{region_type}_{window_size}_{region_counter}\"\n",
    "\n",
    "        # 1. Insert into Region\n",
    "        region_doc = {\n",
    "            \"id\": region_id,\n",
    "            \"chrom\": row[\"chrom\"],\n",
    "            \"start\": int(row[\"start\"]),\n",
    "            \"end\": int(row[\"end\"]),\n",
    "            \"strand\": row[\"strand\"],\n",
    "            \"cell_line\": cell_line,\n",
    "            \"region_type\": region_type,\n",
    "            \"window_size\": int(window_size)\n",
    "        }\n",
    "        region_col.insert_one(region_doc)\n",
    "\n",
    "        # 2. Insert into EpigenomicFeatures\n",
    "        feature_doc = {\n",
    "            \"id\": region_id + \"_f\",\n",
    "            \"region_id\": region_id,\n",
    "            \"TPM\": float(row[\"TPM\"])\n",
    "        }\n",
    "\n",
    "        # Dynamically add the remaining marks\n",
    "        for col in df.columns:\n",
    "            if col not in [\"chrom\", \"start\", \"end\", \"strand\", \"TPM\"]:\n",
    "                feature_doc[col] = float(row[col]) if pd.notna(row[col]) else None\n",
    "\n",
    "        feature_col.insert_one(feature_doc)\n",
    "        region_counter += 1\n",
    "\n",
    "print(\"✅ Ingestion complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 1142428 regions with window_size=256\n",
      "Data extraction preparation took 7.56 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching features: 100%|██████████| 229/229 [11:53<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 1142428 feature documents\n",
      "Total data extraction took 722.26 sec\n",
      "Feature keys found: ['ARID1B', 'ARID2', 'ARID3A', 'ARID3B', 'ARID4A', 'ARID4B', 'ARID5B', 'BRD4', 'CHD1', 'CHD2', 'CHD4', 'CHD7', 'CTCF', 'CTCFL', 'DNMT1', 'DNMT3B', 'EED', 'ESR1', 'ETS1', 'ETS2', 'EZH2', 'FOXA1', 'FOXA2', 'FOXA3', 'GATA1', 'GATA2', 'GATA3', 'H3K27ac', 'H3K27me3', 'H3K36me3', 'H3K4me1', 'H3K4me2', 'H3K4me3', 'H3K79me2', 'H3K9ac', 'H3K9me2', 'H3K9me3', 'H4K20me1', 'HDAC1', 'HDAC2', 'HDAC3', 'HDAC6', 'HDAC8', 'KAT2A', 'KAT2B', 'KAT7', 'KAT8', 'KDM1A', 'KDM2A', 'KDM3A', 'KDM4B', 'KDM5A', 'KDM5B', 'KDM6A', 'NR3C1', 'SMARCA4', 'SMARCB1', 'SUZ12']\n",
      "X shape: (1142428, 58), y shape: (1142428,)\n",
      "Task 1 train size: 567203, test size: 141801\n",
      "Task 2 train size: 284659, test size: 71165\n",
      "Task 3 train size: 354396, test size: 88599\n",
      "Task 4 train size: 71852, test size: 17963\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers, optimizers, losses, metrics, Model\n",
    "from tqdm import tqdm  # Added for progress tracking\n",
    "\n",
    "# --- Configs ---\n",
    "WINDOW_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 0.001\n",
    "LEARNING_RATE_DECAY = 0.1\n",
    "L2_REG = 0.0\n",
    "OPTIMIZER = 'sgd'\n",
    "MONGO_BATCH_SIZE = 5000  # <-- NEW: batch size for querying MongoDB\n",
    "\n",
    "# MongoDB connection\n",
    "client = MongoClient('mongodb://localhost:27017')\n",
    "db = client['epigenomic_reduction']\n",
    "epigenomic_collection = db['EpigenomicFeatures']\n",
    "region_collection = db['Region']\n",
    "\n",
    "# -------------------------\n",
    "# Step 1: Get region_ids with window_size=256\n",
    "start_time = time.time()\n",
    "region_cursor = region_collection.find({'window_size': WINDOW_SIZE}, {'id': 1})\n",
    "region_ids_256 = [doc['id'] for doc in region_cursor]\n",
    "print(f\"Filtered {len(region_ids_256)} regions with window_size=256\")\n",
    "extract_time = time.time() - start_time\n",
    "print(f\"Data extraction preparation took {extract_time:.2f} sec\")\n",
    "\n",
    "# Step 2: Extract EpigenomicFeatures in batches\n",
    "start_time = time.time()\n",
    "projection = {'_id': 0, 'id': 0}  # Exclude large/irrelevant fields\n",
    "feature_list = []\n",
    "\n",
    "for i in tqdm(range(0, len(region_ids_256), MONGO_BATCH_SIZE), desc=\"Fetching features\"):\n",
    "    batch_ids = region_ids_256[i:i + MONGO_BATCH_SIZE]\n",
    "    cursor = epigenomic_collection.find({'region_id': {'$in': batch_ids}}, projection).batch_size(1000)\n",
    "    feature_list.extend(cursor)\n",
    "\n",
    "print(f\"Extracted {len(feature_list)} feature documents\")\n",
    "extract_time += (time.time() - start_time)\n",
    "print(f\"Total data extraction took {extract_time:.2f} sec\")\n",
    "\n",
    "# Step 3: Identify all possible feature keys (excluding metadata)\n",
    "exclude_keys = {'_id', 'id', 'region_id', 'TPM'}\n",
    "all_feature_keys = set()\n",
    "for doc in feature_list:\n",
    "    all_feature_keys.update(set(doc.keys()) - exclude_keys)\n",
    "\n",
    "all_feature_keys = sorted(all_feature_keys)\n",
    "print(f\"Feature keys found: {all_feature_keys}\")\n",
    "\n",
    "# Step 4: Create dataset (X, y) with missing features = 0\n",
    "X = []\n",
    "y = []\n",
    "region_types = []\n",
    "\n",
    "# Create region_type map\n",
    "region_map = {}\n",
    "for doc in region_collection.find({'window_size': WINDOW_SIZE}, {'id': 1, 'region_type': 1}):\n",
    "    region_map[doc['id']] = doc['region_type']\n",
    "\n",
    "for doc in feature_list:\n",
    "    features = [doc.get(key, 0) for key in all_feature_keys]\n",
    "    X.append(features)\n",
    "    y.append(doc['TPM'])\n",
    "    region_types.append(region_map.get(doc['region_id'], None))\n",
    "\n",
    "X = np.array(X, dtype=np.float32)\n",
    "y = np.array(y, dtype=np.float32)\n",
    "region_types = np.array(region_types)\n",
    "\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "\n",
    "# --- Prepare classification tasks ---\n",
    "def prepare_task_data(region_types, y, X, pos_class, neg_class, pos_region_type, neg_region_type):\n",
    "    mask = (\n",
    "        ((region_types == pos_region_type) & (y == pos_class)) |\n",
    "        ((region_types == neg_region_type) & (y == neg_class))\n",
    "    )\n",
    "    X_task = X[mask]\n",
    "    y_task = y[mask]\n",
    "    y_task_bin = ((region_types[mask] == pos_region_type) & (y[mask] == pos_class)).astype(np.float32)\n",
    "    return train_test_split(X_task, y_task_bin, test_size=0.2, random_state=42)\n",
    "\n",
    "# Task 1: inactive enhancer vs inactive promoter\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = prepare_task_data(\n",
    "    region_types, y, X,\n",
    "    pos_class=0, neg_class=0,\n",
    "    pos_region_type='enhancer', neg_region_type='promoter'\n",
    ")\n",
    "\n",
    "# Task 2: active promoter vs inactive promoter\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = prepare_task_data(\n",
    "    region_types, y, X,\n",
    "    pos_class=1, neg_class=0,\n",
    "    pos_region_type='promoter', neg_region_type='promoter'\n",
    ")\n",
    "\n",
    "# Task 3: active enhancer vs inactive enhancer\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = prepare_task_data(\n",
    "    region_types, y, X,\n",
    "    pos_class=1, neg_class=0,\n",
    "    pos_region_type='enhancer', neg_region_type='enhancer'\n",
    ")\n",
    "\n",
    "# Task 4: active enhancer vs active promoter\n",
    "X_train_4, X_test_4, y_train_4, y_test_4 = prepare_task_data(\n",
    "    region_types, y, X,\n",
    "    pos_class=1, neg_class=1,\n",
    "    pos_region_type='enhancer', neg_region_type='promoter'\n",
    ")\n",
    "\n",
    "print(f\"Task 1 train size: {len(y_train_1)}, test size: {len(y_test_1)}\")\n",
    "print(f\"Task 2 train size: {len(y_train_2)}, test size: {len(y_test_2)}\")\n",
    "print(f\"Task 3 train size: {len(y_train_3)}, test size: {len(y_test_3)}\")\n",
    "print(f\"Task 4 train size: {len(y_train_4)}, test size: {len(y_test_4)}\")\n",
    "\n",
    "# --- Build the FFNN model ---\n",
    "def create_model(input_dim):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(16, activation='relu', kernel_regularizer=regularizers.l2(L2_REG), input_shape=(input_dim,)),\n",
    "        layers.Dense(4, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "        layers.Dense(2, activation='relu', kernel_regularizer=regularizers.l2(L2_REG)),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=LEARNING_RATE,\n",
    "        decay_steps=1000,\n",
    "        decay_rate=LEARNING_RATE_DECAY,\n",
    "        staircase=True\n",
    "    )\n",
    "    optimizer = optimizers.SGD(learning_rate=lr_schedule)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=losses.BinaryCrossentropy(),\n",
    "                  metrics=[metrics.BinaryAccuracy()])\n",
    "    return model\n",
    "\n",
    "# --- Training function with timing ---\n",
    "def train_and_evaluate(X_train, y_train, X_test, y_test):\n",
    "    model = create_model(X_train.shape[1])\n",
    "    \n",
    "    # --- Training ---\n",
    "    start_train = time.time()\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        epochs=EPOCHS,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        verbose=2)\n",
    "    train_time = time.time() - start_train\n",
    "    print(f\"Training took {train_time:.2f} seconds\")\n",
    "    \n",
    "    # --- Evaluate on test set ---\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    return model, history, test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configs ---\n",
    "EPOCHS = 5\n",
    "LEARNING_RATE = 0.001\n",
    "LEARNING_RATE_DECAY = 0.1\n",
    "L2_REG = 0.0\n",
    "OPTIMIZER = 'sgd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "17726/17726 - 18s - 1ms/step - binary_accuracy: 0.5770 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 2/5\n",
      "17726/17726 - 17s - 958us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 3/5\n",
      "17726/17726 - 17s - 974us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 4/5\n",
      "17726/17726 - 17s - 981us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 5/5\n",
      "17726/17726 - 17s - 942us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Training took 86.76 seconds\n",
      "Test Accuracy: 0.5656\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --- Example: train task 1 ---\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model_1, history_1 \u001b[38;5;241m=\u001b[39m train_and_evaluate(X_train_1, y_train_1, X_test_1, y_test_1)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# --- Example: train task 1 ---\n",
    "model_1, history_1 = train_and_evaluate(X_train_1, y_train_1, X_test_1, y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8896/8896 - 10s - 1ms/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 2/5\n",
      "8896/8896 - 9s - 1ms/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 3/5\n",
      "8896/8896 - 9s - 960us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 4/5\n",
      "8896/8896 - 9s - 980us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 5/5\n",
      "8896/8896 - 9s - 1ms/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Training took 44.97 seconds\n",
      "Test Accuracy: 0.8672\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --- Train task 2 ---\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model_2, history_2 \u001b[38;5;241m=\u001b[39m train_and_evaluate(X_train_2, y_train_2, X_test_2, y_test_2)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# --- Train task 2 ---\n",
    "model_2, history_2 = train_and_evaluate(X_train_2, y_train_2, X_test_2, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11075/11075 - 11s - 1ms/step - binary_accuracy: 0.9036 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 2/5\n",
      "11075/11075 - 11s - 955us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 3/5\n",
      "11075/11075 - 10s - 878us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 4/5\n",
      "11075/11075 - 11s - 986us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 5/5\n",
      "11075/11075 - 13s - 1ms/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Training took 55.86 seconds\n",
      "Test Accuracy: 0.9057\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --- Train task 3 ---\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model_3, history_3 \u001b[38;5;241m=\u001b[39m train_and_evaluate(X_train_3, y_train_3, X_test_3, y_test_3)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Train task 3 ---\n",
    "model_3, history_3 = train_and_evaluate(X_train_3, y_train_3, X_test_3, y_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2246/2246 - 3s - 1ms/step - binary_accuracy: 0.5246 - loss: 0.7023 - val_binary_accuracy: 0.5255 - val_loss: 0.6919\n",
      "Epoch 2/5\n",
      "2246/2246 - 2s - 1ms/step - binary_accuracy: 0.5273 - loss: 0.6917 - val_binary_accuracy: 0.5255 - val_loss: 0.6919\n",
      "Epoch 3/5\n",
      "2246/2246 - 2s - 1ms/step - binary_accuracy: 0.5273 - loss: 0.6917 - val_binary_accuracy: 0.5255 - val_loss: 0.6919\n",
      "Epoch 4/5\n",
      "2246/2246 - 2s - 1ms/step - binary_accuracy: 0.5273 - loss: 0.6917 - val_binary_accuracy: 0.5255 - val_loss: 0.6919\n",
      "Epoch 5/5\n",
      "2246/2246 - 2s - 1ms/step - binary_accuracy: 0.5273 - loss: 0.6917 - val_binary_accuracy: 0.5255 - val_loss: 0.6919\n",
      "Training took 12.16 seconds\n",
      "Test Accuracy: 0.5255\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --- Train task 4 ---\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model_4, history_4 \u001b[38;5;241m=\u001b[39m train_and_evaluate(X_train_4, y_train_4, X_test_4, y_test_4)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# --- Train task 4 ---\n",
    "model_4, history_4 = train_and_evaluate(X_train_4, y_train_4, X_test_4, y_test_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "17726/17726 - 18s - 1ms/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 2/64\n",
      "17726/17726 - 16s - 894us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 3/64\n",
      "17726/17726 - 15s - 872us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 4/64\n",
      "17726/17726 - 16s - 875us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 5/64\n",
      "17726/17726 - 15s - 872us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 6/64\n",
      "17726/17726 - 15s - 869us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 7/64\n",
      "17726/17726 - 15s - 865us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 8/64\n",
      "17726/17726 - 15s - 866us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 9/64\n",
      "17726/17726 - 15s - 859us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 10/64\n",
      "17726/17726 - 15s - 872us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 11/64\n",
      "17726/17726 - 15s - 866us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 12/64\n",
      "17726/17726 - 15s - 869us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 13/64\n",
      "17726/17726 - 15s - 859us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 14/64\n",
      "17726/17726 - 15s - 859us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 15/64\n",
      "17726/17726 - 15s - 861us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 16/64\n",
      "17726/17726 - 15s - 865us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 17/64\n",
      "17726/17726 - 15s - 859us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 18/64\n",
      "17726/17726 - 15s - 855us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 19/64\n",
      "17726/17726 - 15s - 848us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 20/64\n",
      "17726/17726 - 15s - 858us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 21/64\n",
      "17726/17726 - 15s - 854us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 22/64\n",
      "17726/17726 - 15s - 856us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 23/64\n",
      "17726/17726 - 15s - 857us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 24/64\n",
      "17726/17726 - 15s - 861us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 25/64\n",
      "17726/17726 - 15s - 868us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 26/64\n",
      "17726/17726 - 15s - 867us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 27/64\n",
      "17726/17726 - 15s - 853us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 28/64\n",
      "17726/17726 - 15s - 854us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 29/64\n",
      "17726/17726 - 15s - 862us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 30/64\n",
      "17726/17726 - 15s - 863us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 31/64\n",
      "17726/17726 - 15s - 857us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 32/64\n",
      "17726/17726 - 15s - 856us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 33/64\n",
      "17726/17726 - 15s - 857us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 34/64\n",
      "17726/17726 - 16s - 890us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 35/64\n",
      "17726/17726 - 15s - 866us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 36/64\n",
      "17726/17726 - 15s - 851us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 37/64\n",
      "17726/17726 - 15s - 856us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 38/64\n",
      "17726/17726 - 15s - 860us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 39/64\n",
      "17726/17726 - 15s - 861us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 40/64\n",
      "17726/17726 - 15s - 850us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 41/64\n",
      "17726/17726 - 15s - 862us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 42/64\n",
      "17726/17726 - 15s - 860us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 43/64\n",
      "17726/17726 - 15s - 858us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 44/64\n",
      "17726/17726 - 15s - 846us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 45/64\n",
      "17726/17726 - 15s - 854us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 46/64\n",
      "17726/17726 - 15s - 870us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 47/64\n",
      "17726/17726 - 15s - 865us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 48/64\n",
      "17726/17726 - 15s - 857us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 49/64\n",
      "17726/17726 - 15s - 864us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 50/64\n",
      "17726/17726 - 15s - 872us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 51/64\n",
      "17726/17726 - 15s - 870us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 52/64\n",
      "17726/17726 - 15s - 856us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 53/64\n",
      "17726/17726 - 15s - 848us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 54/64\n",
      "17726/17726 - 15s - 853us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 55/64\n",
      "17726/17726 - 15s - 862us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 56/64\n",
      "17726/17726 - 15s - 852us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 57/64\n",
      "17726/17726 - 15s - 854us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 58/64\n",
      "17726/17726 - 15s - 857us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 59/64\n",
      "17726/17726 - 15s - 857us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 60/64\n",
      "17726/17726 - 15s - 850us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 61/64\n",
      "17726/17726 - 15s - 856us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 62/64\n",
      "17726/17726 - 15s - 859us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 63/64\n",
      "17726/17726 - 15s - 857us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Epoch 64/64\n",
      "17726/17726 - 15s - 856us/step - binary_accuracy: 0.5647 - loss: nan - val_binary_accuracy: 0.5656 - val_loss: nan\n",
      "Training took 979.73 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Example: train task 1 ---\n",
    "model_1, history_1 = train_and_evaluate(X_train_1, y_train_1, X_test_1, y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "8896/8896 - 9s - 960us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 2/64\n",
      "8896/8896 - 8s - 876us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 3/64\n",
      "8896/8896 - 8s - 878us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 4/64\n",
      "8896/8896 - 8s - 880us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 5/64\n",
      "8896/8896 - 8s - 862us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 6/64\n",
      "8896/8896 - 8s - 893us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 7/64\n",
      "8896/8896 - 8s - 861us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 8/64\n",
      "8896/8896 - 8s - 866us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 9/64\n",
      "8896/8896 - 8s - 876us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 10/64\n",
      "8896/8896 - 8s - 866us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 11/64\n",
      "8896/8896 - 8s - 898us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 12/64\n",
      "8896/8896 - 8s - 872us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 13/64\n",
      "8896/8896 - 8s - 876us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 14/64\n",
      "8896/8896 - 8s - 877us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 15/64\n",
      "8896/8896 - 8s - 871us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 16/64\n",
      "8896/8896 - 8s - 882us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 17/64\n",
      "8896/8896 - 8s - 872us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 18/64\n",
      "8896/8896 - 8s - 863us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 19/64\n",
      "8896/8896 - 8s - 872us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 20/64\n",
      "8896/8896 - 8s - 865us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 21/64\n",
      "8896/8896 - 8s - 858us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 22/64\n",
      "8896/8896 - 8s - 864us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 23/64\n",
      "8896/8896 - 8s - 863us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 24/64\n",
      "8896/8896 - 8s - 869us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 25/64\n",
      "8896/8896 - 8s - 864us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 26/64\n",
      "8896/8896 - 8s - 867us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 27/64\n",
      "8896/8896 - 8s - 883us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 28/64\n",
      "8896/8896 - 8s - 871us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 29/64\n",
      "8896/8896 - 8s - 860us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 30/64\n",
      "8896/8896 - 8s - 867us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 31/64\n",
      "8896/8896 - 8s - 859us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 32/64\n",
      "8896/8896 - 8s - 859us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 33/64\n",
      "8896/8896 - 8s - 863us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 34/64\n",
      "8896/8896 - 8s - 862us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 35/64\n",
      "8896/8896 - 8s - 867us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 36/64\n",
      "8896/8896 - 8s - 866us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 37/64\n",
      "8896/8896 - 8s - 866us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 38/64\n",
      "8896/8896 - 8s - 869us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 39/64\n",
      "8896/8896 - 8s - 865us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 40/64\n",
      "8896/8896 - 8s - 868us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 41/64\n",
      "8896/8896 - 8s - 864us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 42/64\n",
      "8896/8896 - 8s - 866us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 43/64\n",
      "8896/8896 - 8s - 872us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 44/64\n",
      "8896/8896 - 8s - 870us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 45/64\n",
      "8896/8896 - 8s - 859us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 46/64\n",
      "8896/8896 - 8s - 858us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 47/64\n",
      "8896/8896 - 8s - 859us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 48/64\n",
      "8896/8896 - 8s - 872us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 49/64\n",
      "8896/8896 - 8s - 863us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 50/64\n",
      "8896/8896 - 8s - 872us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 51/64\n",
      "8896/8896 - 8s - 870us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 52/64\n",
      "8896/8896 - 8s - 860us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 53/64\n",
      "8896/8896 - 8s - 859us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 54/64\n",
      "8896/8896 - 8s - 867us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 55/64\n",
      "8896/8896 - 8s - 862us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 56/64\n",
      "8896/8896 - 8s - 867us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 57/64\n",
      "8896/8896 - 8s - 861us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 58/64\n",
      "8896/8896 - 8s - 865us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 59/64\n",
      "8896/8896 - 8s - 861us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 60/64\n",
      "8896/8896 - 8s - 864us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 61/64\n",
      "8896/8896 - 8s - 863us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 62/64\n",
      "8896/8896 - 8s - 869us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 63/64\n",
      "8896/8896 - 8s - 857us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Epoch 64/64\n",
      "8896/8896 - 8s - 867us/step - binary_accuracy: 0.8669 - loss: nan - val_binary_accuracy: 0.8672 - val_loss: nan\n",
      "Training took 495.06 seconds\n"
     ]
    }
   ],
   "source": [
    "# --- Train task 2 ---\n",
    "model_2, history_2 = train_and_evaluate(X_train_2, y_train_2, X_test_2, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "11075/11075 - 10s - 942us/step - binary_accuracy: 0.9042 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 2/64\n",
      "11075/11075 - 10s - 872us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 3/64\n",
      "11075/11075 - 10s - 867us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 4/64\n",
      "11075/11075 - 10s - 868us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 5/64\n",
      "11075/11075 - 10s - 874us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 6/64\n",
      "11075/11075 - 10s - 873us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 7/64\n",
      "11075/11075 - 10s - 872us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 8/64\n",
      "11075/11075 - 10s - 865us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 9/64\n",
      "11075/11075 - 10s - 859us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 10/64\n",
      "11075/11075 - 10s - 861us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 11/64\n",
      "11075/11075 - 9s - 857us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 12/64\n",
      "11075/11075 - 10s - 865us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 13/64\n",
      "11075/11075 - 10s - 863us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 14/64\n",
      "11075/11075 - 10s - 868us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 15/64\n",
      "11075/11075 - 10s - 867us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 16/64\n",
      "11075/11075 - 10s - 870us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 17/64\n",
      "11075/11075 - 10s - 871us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 18/64\n",
      "11075/11075 - 10s - 860us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 19/64\n",
      "11075/11075 - 10s - 865us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 20/64\n",
      "11075/11075 - 10s - 880us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 21/64\n",
      "11075/11075 - 9s - 857us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 22/64\n",
      "11075/11075 - 10s - 874us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 23/64\n",
      "11075/11075 - 10s - 877us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 24/64\n",
      "11075/11075 - 10s - 868us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 25/64\n",
      "11075/11075 - 10s - 878us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 26/64\n",
      "11075/11075 - 10s - 863us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 27/64\n",
      "11075/11075 - 10s - 868us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 28/64\n",
      "11075/11075 - 10s - 869us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 29/64\n",
      "11075/11075 - 10s - 866us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 30/64\n",
      "11075/11075 - 10s - 859us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 31/64\n",
      "11075/11075 - 10s - 862us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 32/64\n",
      "11075/11075 - 10s - 874us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 33/64\n",
      "11075/11075 - 10s - 860us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 34/64\n",
      "11075/11075 - 10s - 861us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 35/64\n",
      "11075/11075 - 10s - 858us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 36/64\n",
      "11075/11075 - 10s - 861us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 37/64\n",
      "11075/11075 - 9s - 857us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 38/64\n",
      "11075/11075 - 10s - 862us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 39/64\n",
      "11075/11075 - 9s - 857us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 40/64\n",
      "11075/11075 - 9s - 856us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 41/64\n",
      "11075/11075 - 9s - 854us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 42/64\n",
      "11075/11075 - 9s - 856us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 43/64\n",
      "11075/11075 - 9s - 854us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 44/64\n",
      "11075/11075 - 10s - 863us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 45/64\n",
      "11075/11075 - 10s - 861us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 46/64\n",
      "11075/11075 - 10s - 860us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 47/64\n",
      "11075/11075 - 9s - 856us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 48/64\n",
      "11075/11075 - 10s - 862us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 49/64\n",
      "11075/11075 - 10s - 862us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 50/64\n",
      "11075/11075 - 10s - 881us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 51/64\n",
      "11075/11075 - 10s - 871us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 52/64\n",
      "11075/11075 - 10s - 871us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 53/64\n",
      "11075/11075 - 10s - 860us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 54/64\n",
      "11075/11075 - 10s - 862us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 55/64\n",
      "11075/11075 - 10s - 871us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 56/64\n",
      "11075/11075 - 10s - 859us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 57/64\n",
      "11075/11075 - 10s - 870us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 58/64\n",
      "11075/11075 - 10s - 862us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 59/64\n",
      "11075/11075 - 10s - 861us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 60/64\n",
      "11075/11075 - 10s - 862us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 61/64\n",
      "11075/11075 - 10s - 864us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 62/64\n",
      "11075/11075 - 9s - 857us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 63/64\n",
      "11075/11075 - 10s - 862us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Epoch 64/64\n",
      "11075/11075 - 10s - 861us/step - binary_accuracy: 0.9037 - loss: nan - val_binary_accuracy: 0.9057 - val_loss: nan\n",
      "Training took 613.86 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Train task 3 ---\n",
    "model_3, history_3 = train_and_evaluate(X_train_3, y_train_3, X_test_3, y_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "2246/2246 - 2s - 1ms/step - binary_accuracy: 0.8310 - loss: 0.4385 - val_binary_accuracy: 0.8593 - val_loss: 0.3942\n",
      "Epoch 2/64\n",
      "2246/2246 - 2s - 919us/step - binary_accuracy: 0.8578 - loss: 0.3968 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 3/64\n",
      "2246/2246 - 2s - 929us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 4/64\n",
      "2246/2246 - 2s - 922us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 5/64\n",
      "2246/2246 - 2s - 912us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 6/64\n",
      "2246/2246 - 2s - 903us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 7/64\n",
      "2246/2246 - 2s - 905us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 8/64\n",
      "2246/2246 - 2s - 893us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 9/64\n",
      "2246/2246 - 2s - 890us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 10/64\n",
      "2246/2246 - 2s - 893us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 11/64\n",
      "2246/2246 - 2s - 895us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 12/64\n",
      "2246/2246 - 2s - 896us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 13/64\n",
      "2246/2246 - 2s - 913us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 14/64\n",
      "2246/2246 - 2s - 894us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 15/64\n",
      "2246/2246 - 2s - 906us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 16/64\n",
      "2246/2246 - 2s - 900us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 17/64\n",
      "2246/2246 - 2s - 891us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 18/64\n",
      "2246/2246 - 2s - 891us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 19/64\n",
      "2246/2246 - 2s - 894us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 20/64\n",
      "2246/2246 - 2s - 877us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 21/64\n",
      "2246/2246 - 2s - 878us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 22/64\n",
      "2246/2246 - 2s - 877us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 23/64\n",
      "2246/2246 - 2s - 903us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 24/64\n",
      "2246/2246 - 2s - 893us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 25/64\n",
      "2246/2246 - 2s - 892us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 26/64\n",
      "2246/2246 - 2s - 890us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 27/64\n",
      "2246/2246 - 2s - 886us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 28/64\n",
      "2246/2246 - 2s - 883us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 29/64\n",
      "2246/2246 - 2s - 880us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 30/64\n",
      "2246/2246 - 2s - 885us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 31/64\n",
      "2246/2246 - 2s - 882us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 32/64\n",
      "2246/2246 - 2s - 876us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 33/64\n",
      "2246/2246 - 2s - 883us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 34/64\n",
      "2246/2246 - 2s - 874us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 35/64\n",
      "2246/2246 - 2s - 874us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 36/64\n",
      "2246/2246 - 2s - 888us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 37/64\n",
      "2246/2246 - 2s - 896us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 38/64\n",
      "2246/2246 - 2s - 876us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 39/64\n",
      "2246/2246 - 2s - 878us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 40/64\n",
      "2246/2246 - 2s - 874us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 41/64\n",
      "2246/2246 - 2s - 875us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 42/64\n",
      "2246/2246 - 2s - 879us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 43/64\n",
      "2246/2246 - 2s - 889us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 44/64\n",
      "2246/2246 - 2s - 881us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 45/64\n",
      "2246/2246 - 2s - 874us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 46/64\n",
      "2246/2246 - 2s - 882us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 47/64\n",
      "2246/2246 - 2s - 877us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 48/64\n",
      "2246/2246 - 2s - 883us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 49/64\n",
      "2246/2246 - 2s - 876us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 50/64\n",
      "2246/2246 - 2s - 880us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 51/64\n",
      "2246/2246 - 2s - 877us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 52/64\n",
      "2246/2246 - 2s - 872us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 53/64\n",
      "2246/2246 - 2s - 874us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 54/64\n",
      "2246/2246 - 2s - 902us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 55/64\n",
      "2246/2246 - 2s - 905us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 56/64\n",
      "2246/2246 - 2s - 903us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 57/64\n",
      "2246/2246 - 2s - 892us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 58/64\n",
      "2246/2246 - 2s - 878us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 59/64\n",
      "2246/2246 - 2s - 881us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 60/64\n",
      "2246/2246 - 2s - 881us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 61/64\n",
      "2246/2246 - 2s - 884us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 62/64\n",
      "2246/2246 - 2s - 930us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 63/64\n",
      "2246/2246 - 2s - 883us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Epoch 64/64\n",
      "2246/2246 - 2s - 893us/step - binary_accuracy: 0.8580 - loss: 0.3963 - val_binary_accuracy: 0.8594 - val_loss: 0.3937\n",
      "Training took 128.52 seconds\n"
     ]
    }
   ],
   "source": [
    "# --- Train task 4 ---\n",
    "model_4, history_4 = train_and_evaluate(X_train_4, y_train_4, X_test_4, y_test_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Scaler pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique features: 58\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------------------\n",
    "# MongoDB Setup\n",
    "# -------------------------------\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"epigenomic_reduction\"]\n",
    "features_collection = db[\"EpigenomicFeatures\"]\n",
    "region_collection = db[\"Region\"]\n",
    "\n",
    "# -------------------------------\n",
    "# Configs\n",
    "# -------------------------------\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 64\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# -------------------------------\n",
    "# Step 1: Extract All Unique Feature Keys\n",
    "# -------------------------------\n",
    "unique_features = set()\n",
    "for doc in features_collection.find({}, {\"_id\": 0}):\n",
    "    for key in doc.keys():\n",
    "        if key not in [\"id\", \"region_id\", \"TPM\"]:\n",
    "            unique_features.add(key)\n",
    "unique_features = sorted(list(unique_features))  # consistent order\n",
    "\n",
    "print(f\"Total unique features: {len(unique_features)}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Step 2: Define Dataset Builder\n",
    "# -------------------------------\n",
    "def build_dataset(tpm_1_type=None, tpm_0_type=None):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    def fetch_features(tpm_val, region_type):\n",
    "        region_ids = region_collection.find(\n",
    "            {\"region_type\": region_type, \"window_size\": 256},\n",
    "            {\"id\": 1, \"_id\": 0}\n",
    "        )\n",
    "        region_ids = set([r[\"id\"] for r in region_ids])\n",
    "\n",
    "        cursor = features_collection.find({\"TPM\": tpm_val})\n",
    "        for doc in cursor:\n",
    "            if doc[\"region_id\"] in region_ids:\n",
    "                row = [doc.get(f, 0.0) for f in unique_features]\n",
    "                label = 1 if tpm_val == 1 else 0\n",
    "                X.append(row)\n",
    "                y.append(label)\n",
    "\n",
    "    if tpm_0_type:\n",
    "        fetch_features(0, tpm_0_type)\n",
    "    if tpm_1_type:\n",
    "        fetch_features(1, tpm_1_type)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 3: Define FFNN\n",
    "# -------------------------------\n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# -------------------------------\n",
    "# Step 4: Train Model\n",
    "# -------------------------------\n",
    "def train_model(X, y, task_name):\n",
    "    print(f\"\\n=== Training: {task_name} ===\")\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Scale\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Convert to tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    model = FFNN(X.shape[1])\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X_test_tensor).round()\n",
    "        acc = (preds.eq(y_test_tensor)).float().mean().item()\n",
    "        print(f\"{task_name} Accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training: Task 1: Inactive Enhancer vs Inactive Promoter ===\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([X1, X2])\n\u001b[0;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([y1, y2])\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTask 1: Inactive Enhancer vs Inactive Promoter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 125\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(X, y, task_name)\u001b[0m\n\u001b[0;32m    123\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    124\u001b[0m preds \u001b[38;5;241m=\u001b[39m model(xb)\n\u001b[1;32m--> 125\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    127\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:699\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:3569\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3566\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m   3567\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[1;32m-> 3569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "# Task 1: Inactive Enhancer vs Inactive Promoter\n",
    "X1, y1 = build_dataset(tpm_0_type=\"enhancer\")\n",
    "X2, y2 = build_dataset(tpm_0_type=\"promoter\")\n",
    "X = np.concatenate([X1, X2])\n",
    "y = np.concatenate([y1, y2])\n",
    "train_model(X, y, \"Task 1: Inactive Enhancer vs Inactive Promoter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Active Promoter vs Inactive Promoter\n",
    "X1, y1 = build_dataset(tpm_1_type=\"promoter\")\n",
    "X2, y2 = build_dataset(tpm_0_type=\"promoter\")\n",
    "X = np.concatenate([X1, X2])\n",
    "y = np.concatenate([y1, y2])\n",
    "train_model(X, y, \"Task 2: Active Promoter vs Inactive Promoter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Active Enhancer vs Inactive Enhancer\n",
    "X1, y1 = build_dataset(tpm_1_type=\"enhancer\")\n",
    "X2, y2 = build_dataset(tpm_0_type=\"enhancer\")\n",
    "X = np.concatenate([X1, X2])\n",
    "y = np.concatenate([y1, y2])\n",
    "train_model(X, y, \"Task 3: Active Enhancer vs Inactive Enhancer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Active Enhancer vs Active Promoter\n",
    "X1, y1 = build_dataset(tpm_1_type=\"enhancer\")\n",
    "X2, y2 = build_dataset(tpm_1_type=\"promoter\")\n",
    "X = np.concatenate([X1, X2])\n",
    "y = np.concatenate([y1, y2])\n",
    "train_model(X, y, \"Task 4: Active Enhancer vs Active Promoter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
